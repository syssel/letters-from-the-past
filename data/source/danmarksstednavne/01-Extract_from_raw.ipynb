{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"delimiter\":\"\\t\",\n",
    "    \"header\": 0,\n",
    "    \"usecols\":[\"id\", \"DSArtikelID\", \"kilde_ID\", \"kildexml\", \"datering\", \"kildeopslag\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kildeformer = pd.read_csv(\"data/danmarksstednavne_Kildeformer.csv\", **config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"usecols\"] = [\"id\", \"DSId\", \"opslagsform\", \"toponummer\", \"GEO_X_WGS84_32N\", \"GEO_Y_WGS84_32N\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opslagsformer = pd.read_csv(\"data/danmarksstednavne_DSArtikel.csv\", **config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kildeformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(kildeformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(kildeformer.datering).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_year(date):\n",
    "    \n",
    "    # Clean data\n",
    "    date = re.sub(\"[\\[\\]\\<\\>]\", \"\", date) # e.g., 17[96] 133<4>\n",
    "    \n",
    "    pattern = re.compile(r\"(?P<from_to>(?P<century_from>[12]\\d)(?P<decade_from>\\d\\d)( *[-–-] *(?P<century_to>[12]\\d)?(?P<decade_to>\\d\\d))?)+\")\n",
    "    matches = re.finditer(pattern, date)\n",
    "    \n",
    "    years = []\n",
    "    for match in matches:\n",
    "        year_from = int(match[\"century_from\"]+match[\"decade_from\"])\n",
    "        year_to = None\n",
    "        \n",
    "        # 1243-1250\n",
    "        if match[\"century_to\"]:\n",
    "            year_to = int(match[\"century_to\"]+match[\"decade_to\"])\n",
    "\n",
    "        # 1243-50\n",
    "        elif match[\"decade_to\"]:\n",
    "            year_to = int(match[\"century_from\"]+match[\"decade_to\"])\n",
    "        \n",
    "        if year_to: \n",
    "            #assert year_from<=year_to, (match[\"from_to\"], year_from, year_to, date)\n",
    "            if year_from>year_to: print((match[\"from_to\"], year_from, year_to, date))\n",
    "\n",
    "        years.append((year_from, year_to))\n",
    "   \n",
    "    return years\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kildeformer[\"date_from\"] = None\n",
    "kildeformer[\"date_to\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_entries = pd.DataFrame(columns=kildeformer.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from_to = []\n",
    "not_matched = []\n",
    "for index, row in kildeformer.iterrows():\n",
    "    print(index, end=\"\\r\")\n",
    "    \n",
    "    if str(row.datering) == \"nan\":\n",
    "        from_to.append((None,None))\n",
    "        continue\n",
    "\n",
    "    parsed_years = parse_year(str(row.datering))\n",
    "    \n",
    "    if not parsed_years: \n",
    "        not_matched.append((index, row.datering))\n",
    "        from_to.append((None,None))\n",
    "        continue\n",
    "    \n",
    "    from_to.append(parsed_years.pop(0)) # Save to column, and apply later (faster)\n",
    "    \n",
    "    for date_from, date_to in parsed_years:\n",
    "        new_row = row.copy()\n",
    "        new_row.date_from, new_row.date_to = date_from, date_to\n",
    "        new_entries = new_entries.append(new_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kildeformer[\"date_from\"] = list(map(itemgetter(0), from_to))\n",
    "kildeformer[\"date_to\"] = list(map(itemgetter(1), from_to))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_kildeformer = kildeformer.append(new_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_kildeformer[\"date_from\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_kildeformer[\"date_from\"].min(), new_kildeformer[\"date_from\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "out = plt.hist(new_kildeformer[\"date_from\"], bins=20, range=(1000,1600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(not_matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(list(map(itemgetter(1), not_matched))).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append opslagsform and geo-location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_dated = new_kildeformer[new_kildeformer['date_from'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opslag = []\n",
    "toponumre = []\n",
    "geo_x = []\n",
    "geo_y = []\n",
    "\n",
    "for index, row in only_dated.iterrows():\n",
    "    print(index, end=\"\\r\")    \n",
    "    artikel = opslagsformer.loc[opslagsformer['id'] == row.DSArtikelID]\n",
    "    if not artikel.empty:\n",
    "        opslag.append(artikel.opslagsform.values[0])\n",
    "        toponumre.append(artikel.toponummer.values[0])\n",
    "        geo_x.append(artikel.GEO_X_WGS84_32N.values[0])\n",
    "        geo_y.append(artikel.GEO_Y_WGS84_32N.values[0])\n",
    "    else:\n",
    "        opslag.append(np.nan)\n",
    "        toponumre.append(np.nan)\n",
    "        geo_x.append(np.nan)\n",
    "        geo_y.append(np.nan)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_dated[\"opslagsform\"] = opslag\n",
    "only_dated[\"toponummer\"] = toponumre\n",
    "only_dated[\"GEO_X_WGS84_32N\"] = geo_x\n",
    "only_dated[\"GEO_Y_WGS84_32N\"] = geo_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_dated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grapheme parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_opslag = only_dated[only_dated['kildeopslag'].notnull()]\n",
    "del new_kildeformer\n",
    "del only_dated\n",
    "only_opslag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_graphs(name, opslagsform):\n",
    "    graphs = []\n",
    "    queue = list(name)\n",
    "    graphs.append(queue.pop(0))\n",
    "    caught = False\n",
    "    \n",
    "    # Complex graphs\n",
    "    suffixes = [\"h\"]\n",
    "    combinators = list(\"ptkcbdg\")\n",
    "    \n",
    "    opslag_exceptions = [\"holm\", \"hoved\", \"have\", \"havn\", \"høj\", \"hus\", \"hed\"]\n",
    "    \n",
    "    # Manual exeptions\n",
    "    exceptions=[\"ø\", \"ö\", \"olm\", \"us\", \"üs\", \"uus\", \"eth\", \"ed\", \"av\", \"af\"]\n",
    "    new_e = [\"oolm\", \"ede\", \"eide\",\"aue\", \"ave\", \"auge\", \"ouit\", \"oved\", \"ovi\", \"oed\", \"ods\", \"ollm\", \"ei\", \"ey\", \"ol\", \"alme\",  \"aug\", \"oue\", \"oui\", \"øgh\", \"om\", \"ode\", \"ü\", \"oy\", \"öu\"]\n",
    "    new_1 = [\"øg\", \"off\", \"aus\", \"ove\", \"off\", \"yes\", \"owi\", \"ofv\", \"hywæ\", \"agæ\", \"ega\", \"awe\", \"yffu\", \"øgh\", \"iue\", \"iffue\", \"ifue\", \"if\", \"ws\", \"iw\", \"aun\",\"uß\", \"oi\", \"ye\", \"ws\", \"alm\", \"oft\", \"uie\", \"au\", \"hoff\"]\n",
    "    new_2 = [\"ove\", \"ye\", \"off\", \"au\", \"offu\", \"ow\", \"ofv\", \"yw\", \"uß\", \"age\", \"ega\", \"yffu\", \"ws\", \"hegn\", \"oi\", \"ye\", \"ues\", \"uns\", \"aus\", \"oj\", \"ow\", \"ws\", \"öu\", \"off\", \"uo\", \"ofu\", \"ofv\", \"og\", \"wed\", \"of\", \"ov\", \"oe\", \"uy\", \"iø\" , \"uo\", \"oet\", \"eü\", \"y\"]\n",
    "    exceptions = set(exceptions + new_e+new_1+new_2)\n",
    "    changed = False\n",
    "    while queue:\n",
    "        item = queue.pop(0).lower()\n",
    "\n",
    "        \n",
    "        if graphs[-1] in combinators and item in suffixes:\n",
    "            #check_exceptions =  [opslagsform.endswith(e) for e in exceptions]\n",
    "            next_items = \"\".join(queue)\n",
    "            check_exceptions =[next_items.startswith(e) for e in exceptions]\n",
    "            check_opslag = [e in opslagsform for e in opslag_exceptions]\n",
    "            \n",
    "            if not any(check_opslag):\n",
    "                changed = True                \n",
    "                graphs[-1]+=item\n",
    "            else:\n",
    "                if not any(check_exceptions):\n",
    "                    graphs[-1]+=item\n",
    "                    changed = True\n",
    "                else:\n",
    "                    caught = True\n",
    "                    graphs.append(item)\n",
    "        else:\n",
    "            graphs.append(item)\n",
    "    \n",
    "    return graphs, caught, changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(graphs):\n",
    "    norms = {\n",
    "        \"ch\" : \"kh\",\n",
    "        \"c\"  : \"k\",        \n",
    "        \"bh\" : \"b\",\n",
    "        \"dh\" : \"d\",\n",
    "        \"gh\" : \"g\",\n",
    "    }\n",
    "    return [norms.get(g, g) for g in graphs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = []\n",
    "normalised = []\n",
    "changed = []\n",
    "exceptions = []\n",
    "\n",
    "for index, row in only_opslag.iterrows():\n",
    "    print(index, end=\"\\r\")    \n",
    "    graph, e, c = parse_graphs(row.kildeopslag, row.opslagsform)\n",
    "    graphs.append(\";\".join(graph))\n",
    "    normalised.append(\";\".join(normalise(graph)))\n",
    "    if c:\n",
    "        changed.append((graph, normalised[-1], row.kildeopslag, row.opslagsform))\n",
    "    if e:\n",
    "        exceptions.append((graph, normalised[-1], row.kildeopslag, row.opslagsform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(changed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(exceptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_opslag[\"graphs\"] = graphs\n",
    "only_opslag[\"normalised\"] = normalised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for n in set([\"\\t\".join(n[1:]) for n in prev_changed])-set([\"\\t\".join(n[1:]) for n in changed]):\n",
    "#    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_opslag.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_opslag.to_csv(\"danmarksstednavne.csv\", sep=\"\\t\", columns=[\"kildeopslag\", \"date_from\", \"date_to\", \"opslagsform\", \"graphs\", \"normalised\"], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
